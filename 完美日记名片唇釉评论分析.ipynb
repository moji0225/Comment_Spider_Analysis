{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 期末编程实践：通过Python编程获取和解析互联网中的数据\n",
    "- 采用面向对象编程，建议利用继承和多态特性\n",
    "- 采用接口约定，建议对所有输入输出数据和方法都进行约定\n",
    "- 获取数据量需超过100条，建议格式化输出或存储数据\n",
    "- 代码格式整洁，结构完整，逻辑清晰，结果合理，建议利用更多已学知识"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 项目简介\n",
    "1. 项目名称：口红测评——以完美日记名片唇釉为例  \n",
    "2. 选题原因：此项目具有较强的实用意义，因为大多数女性会很频繁的从网络购物平台购买口红，然而在真实使用之前并无法知道产品实物的颜色、质地等最受关注的性质（除非去线下实体店试过），大多数人是在网红推荐下种草一件商品后购入的，然而很多情况下这些网红的推荐只是产品公司的赞助、推广，要得到最真实的评价，最有效的方式莫过于站在消费者的视角，从“买家秀”中窥得产品的真实使用情况，这正是这个项目想实现的。 \n",
    "3. 项目整体思路：半学期的学习实在不足以支撑起一个很完美的作品，所以作者只能借助所学的一些较为表面的知识，试图达到预期的最终成果。\n",
    "   - 首先，选择从作者常购的京东的美妆旗舰店入手——完美日记旗舰店，选择销量最好的一款口红，对评论进行爬取；\n",
    "   - 进而，选择抓取用户昵称、购入色号、整体打分、评论内容和评论时间数据，这一系列较为关键数据，存入数据库，方便进行后续查询；\n",
    "   - 最后，将购入色号和评论内容单独写入一个文本文档，进行分词处理和词云分析。（这一部分算是心血来潮，也因为没学过花了很多时间……）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 项目展示\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 网络爬虫及数据存入"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先是导入项目需要的所有库："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests      # 用于发送网络请求\n",
    "import pymysql       # 用于连接mysql数据库\n",
    "import numpy as np   # 用于数据处理\n",
    "import jieba         # 用于中文分词\n",
    "from wordcloud import WordCloud\n",
    "import PIL.Image as Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于打算将数据写入mysql数据库，所以进行一个连接操作（这部分代码会在'__main__'函数的部分实现）："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "mysql_obj = pymysql.connect(host = 'localhost',user = 'root',password = 'lm020225',port = 3306,charset='utf8mb4') \n",
    "cur_obj = mysql_obj.cursor()\n",
    "print('数据库连接成功！')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用一个**perfect_diary_comment_spider**类将所有的方法进行封装："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class perfect_diary_comment_spider(object):\n",
    "\n",
    "    # 请求头\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.198 Safari/537.36'\n",
    "    }\n",
    "\n",
    "    def __init__(self, file_name='pdc_raw',database_name='perfect_dairy',):\n",
    "        # 实例化类的时候运行初始化函数\n",
    "        # 打开文件\n",
    "        self.file = open(f'data/final/{file_name}.txt', 'w', encoding='utf-8-sig')  # 新建一个txt文档存入色号和评论数据用于后续词云分析\n",
    "        print(f'正在打开文件{file_name}.txt文件!')\n",
    "        \n",
    "        # 创建数据库\n",
    "        cur_obj.execute(f'drop database if exists {database_name}')\n",
    "        cur_obj.execute(f'create database {database_name}')\n",
    "        mysql_obj.select_db(f'{database_name}')\n",
    "        sql=\"\"\"\n",
    "        create table tb1 \n",
    "        (\n",
    "        id int primary key auto_increment,\n",
    "        nickname varchar(200) not null,\n",
    "        productColor varchar(200) not null,\n",
    "        score int,\n",
    "        comment varchar(500),\n",
    "        creationTime varchar(20)\n",
    "        )\n",
    "        \"\"\"\n",
    "        cur_obj.execute(sql)\n",
    "        print(f'成功创建{database_name}数据库！')\n",
    "\n",
    "        \n",
    "    def parse_one_page(self, url):\n",
    "        '''\n",
    "        单页面评论的爬取\n",
    "        :url: 当前页面的url\n",
    "        :return: 获取当前页面的数据写入数据库和txt文档\n",
    "        '''\n",
    "        # 发起请求\n",
    "        response = requests.get(url, headers=self.headers)\n",
    "        # 获取响应\n",
    "        js_data = response.json()   # type(js_data) = dict\n",
    "        # 提取评论列表\n",
    "        comments_list = js_data['comments']\n",
    "\n",
    "        for comment in comments_list:\n",
    "            # 用户昵称\n",
    "            nickname = comment.get('nickname')\n",
    "            # 口红色号\n",
    "            productColor = comment.get('productColor')\n",
    "            # 评分\n",
    "            score = comment.get('score')\n",
    "            # 评论内容\n",
    "            content = comment.get('content')\n",
    "            content = ' '.join(content.split('\\n'))  # 处理换行符\n",
    "            # 评论时间\n",
    "            creationTime = comment.get('creationTime')\n",
    "\n",
    "            # 把数据写入数据库\n",
    "            cur_obj.execute(\n",
    "                'insert into tb1(id,nickname,productColor,score,comment,creationTime) value(0,(\"%s\"),(\"%s\"),(\"%d\"),(\"%s\"),(\"%s\"))'%(nickname,productColor,score,content,creationTime))\n",
    "            # 把数据写入文件\n",
    "            self.file.write(f'{productColor}\\t{content}\\n')\n",
    "\n",
    "\n",
    "    def parse_all_page(self):\n",
    "        '''\n",
    "        进行翻页操作获取想要页数的评论\n",
    "        :input: 需要的页数数量\n",
    "        :return: 获取全部页面评论\n",
    "        '''\n",
    "        pages_ = int(input('请输入需要获取的页数：'))\n",
    "        for page_num in range(pages_):  # 需要抓取的每一页\n",
    "            # 指定通用的url模板\n",
    "            new_url = f'https://club.jd.com/comment/productPageComments.action?productId=100018482877&score=0&sortType=5&page={page_num}&pageSize=10&isShadowSku=0&rid=0&fold=1'\n",
    "            print(f'正在获取第{page_num}页')\n",
    "\n",
    "            # 调用parse_one_page函数\n",
    "            self.parse_one_page(url=new_url)\n",
    "\n",
    "\n",
    "    def commit_close_mysql(self):\n",
    "        # 提交操作\n",
    "        mysql_obj.commit()\n",
    "        count = cur_obj.execute(\"select * from tb1\")\n",
    "        print(f'数据表中已存储{count}条数据')\n",
    "        # 断开连接\n",
    "        cur_obj.close()\n",
    "        mysql_obj.close()\n",
    "\n",
    "\n",
    "    def close_files(self):\n",
    "        self.file.close()\n",
    "        print('爬虫结束，关闭文件！')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 文本分词和词云分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建**txt_to_wrc**类封装词云分析所需的方法:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class txt_to_wrc(object):\n",
    "\n",
    "    def __init__ (self, file_name = 'pdc_raw', outfile_name = 'pdc_output'):\n",
    "        # 指定文档路径       \n",
    "        self.inputs = open(f'data/final/{file_name}.txt','r',encoding='UTF-8-sig')\n",
    "        self.outputs = open(f'data/final/{outfile_name}.txt','w+',encoding='UTF-8-sig')\n",
    "\n",
    "\n",
    "    def stopwordslist(self,stopwordslist_name = 'hit_stopwords'):\n",
    "        '''\n",
    "        设置停用词表\n",
    "        :stopwordslist_name: 选用的停用词表txt文档名\n",
    "        :return: 将txt文档转为list类型数据\n",
    "        '''\n",
    "        stopwords = [i.strip() for i in open(f'data/final/{stopwordslist_name}.txt', encoding = 'UTF-8-sig').readlines()]\n",
    "        return stopwords\n",
    "\n",
    "\n",
    "    def seg_depart(self,sentence):\n",
    "        '''\n",
    "        中文分词和去除停用词\n",
    "        '''\n",
    "        #对文档中的每一行中文分词\n",
    "        sentence_depart = jieba.lcut(sentence.strip())\n",
    "        # 创建停用词列表\n",
    "        stopwords = self.stopwordslist()\n",
    "        # 输出结果为output\n",
    "        output = ''\n",
    "        # 去除停用词\n",
    "        for word in sentence_depart:\n",
    "            if word not in stopwords:\n",
    "                if word != '\\t':\n",
    "                    output += word\n",
    "                    output += \" \"\n",
    "        return output\n",
    "\n",
    "    def write_into_txt(self):\n",
    "        '''\n",
    "        将分词和去停用词后的结果写入pdc_output\n",
    "        ''' \n",
    "        print(\"正在分词和去除停用词……\")\n",
    "        for line in self.inputs:\n",
    "            line_seg = self.seg_depart(line)\n",
    "            self.outputs.write(line_seg + '\\n')\n",
    "        self.inputs.close()\n",
    "        print(\"分词和去除停用词成功！\")\n",
    "\n",
    "        # 将光标移动至起始位置,省去这一步将导致数据读出为空\n",
    "        self.outputs.seek(0,os.SEEK_SET)\n",
    "        print(self.outputs.tell())    # 显示光标在文档中的位置，返回0为文档开头\n",
    "        \n",
    "\n",
    "    def generate_wcd(self,bg_pic_name = 'mouth',font_name = 'simhei'): \n",
    "        '''\n",
    "        生成词云\n",
    "        '''\n",
    "        # 导入中文字体\n",
    "        font_path = f'data/final/{font_name}.ttf'  \n",
    "        # 读入背景图\n",
    "        bg_pic = np.array(Image.open(f'data/final/{bg_pic_name}.jpg')) \n",
    "\n",
    "        wcd = WordCloud(\n",
    "            font_path = font_path,\n",
    "            mask = bg_pic,\n",
    "            background_color=\"white\",\n",
    "            colormap=\"Reds\",\n",
    "            max_font_size = 120,\n",
    "            stopwords = {'产品质感','产品颜色','产品外观','保湿效果','轻薄程度','持久效果','滋润效果','适合肤色','显色效果','颜色','HOT','NEW'},\n",
    "            repeat = False, \n",
    "            max_words = 100\n",
    "            )\n",
    "\n",
    "        wcd.generate(self.outputs.read())\n",
    "        wcd.to_file('data/final/wcd_image.png')\n",
    "        \n",
    "\n",
    "        self.outputs.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 实例化和得出结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据库连接成功！\n",
      "正在打开文件pdc_raw.txt文件!\n",
      "成功创建perfect_dairy数据库！\n",
      "请输入需要获取的页数：50\n",
      "正在获取第0页\n",
      "正在获取第1页\n",
      "正在获取第2页\n",
      "正在获取第3页\n",
      "正在获取第4页\n",
      "正在获取第5页\n",
      "正在获取第6页\n",
      "正在获取第7页\n",
      "正在获取第8页\n",
      "正在获取第9页\n",
      "正在获取第10页\n",
      "正在获取第11页\n",
      "正在获取第12页\n",
      "正在获取第13页\n",
      "正在获取第14页\n",
      "正在获取第15页\n",
      "正在获取第16页\n",
      "正在获取第17页\n",
      "正在获取第18页\n",
      "正在获取第19页\n",
      "正在获取第20页\n",
      "正在获取第21页\n",
      "正在获取第22页\n",
      "正在获取第23页\n",
      "正在获取第24页\n",
      "正在获取第25页\n",
      "正在获取第26页\n",
      "正在获取第27页\n",
      "正在获取第28页\n",
      "正在获取第29页\n",
      "正在获取第30页\n",
      "正在获取第31页\n",
      "正在获取第32页\n",
      "正在获取第33页\n",
      "正在获取第34页\n",
      "正在获取第35页\n",
      "正在获取第36页\n",
      "正在获取第37页\n",
      "正在获取第38页\n",
      "正在获取第39页\n",
      "正在获取第40页\n",
      "正在获取第41页\n",
      "正在获取第42页\n",
      "正在获取第43页\n",
      "正在获取第44页\n",
      "正在获取第45页\n",
      "正在获取第46页\n",
      "正在获取第47页\n",
      "正在获取第48页\n",
      "正在获取第49页\n",
      "数据表中已存储500条数据\n",
      "爬虫结束，关闭文件！\n",
      "正在分词和去除停用词……\n",
      "分词和去除停用词成功！\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':   \n",
    "    # 连接mysql数据库\n",
    "    mysql_obj = pymysql.connect(host = 'localhost',user = 'root',password = 'lm020225',port = 3306,charset='utf8mb4') \n",
    "    cur_obj = mysql_obj.cursor()\n",
    "    print('数据库连接成功！') \n",
    "  \n",
    "    # 实例化perfect_diary_comment_spider对象\n",
    "    perfect_dairy_spider = perfect_diary_comment_spider()\n",
    "    # 开始爬虫\n",
    "    perfect_dairy_spider.parse_all_page()\n",
    "    # 向mysql提交操作并断开连接\n",
    "    perfect_dairy_spider.commit_close_mysql()\n",
    "    # 关闭文件\n",
    "    perfect_dairy_spider.close_files()\n",
    "\n",
    "    # 实例化txt_to_wrc对象\n",
    "    txt_to_wrc1 = txt_to_wrc()\n",
    "    # 分词和数据清洗\n",
    "    txt_to_wrc1.write_into_txt()\n",
    "    # 生成词云\n",
    "    txt_to_wrc1.generate_wcd()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 结果展示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据库结果：\n",
    "![](data/final/database_perfect_diary_tb1.bmp)\n",
    "\n",
    "词云：\n",
    "![](data/final/wcd_image.png)\n",
    "可以从中看出，完美日记的名片唇釉的【柔雾】系列的呼声最高，外观和包装也很受青睐，好看是出现频率最高的评价"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "49cb93f377a7abe7414b7b0f21fb3017538004a126cf690fb524202736b7fb92"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
